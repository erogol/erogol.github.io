---
layout: post
title: Potential risks and misuses of ChatGPT, today and tomorrow.
description: Thoughts on the potential challenges and future implications of AI technologies like ChatGPT today.
summary:
tags: AI, thoughts, GPT, ChatGPT, risks
minute: 4
---

<figure>
    <img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56aa910a-5612-48a1-9c5a-b77ae4ced20b_1024x1024.png" width="100%" />
    <figcaption>Generated by Stable Diffusion with â€œa robot handshaking with a human.</figcaption>
</figure>

(You can also see this on my [substack](https://erogol.substack.com/).)

### Privacy violation

Stealing private information (credit cards, passwords). Simply ask ChatGPT for bank login credentials, credit card numbers, social security numbers, etc.

ðŸ”— https://www.bankinfosecurity.com/chatgpt-exposed-payment-card-data-subscribers-a-21528

The advent of AI technologies like ChatGPT has raised significant privacy concerns. As these models interact with users, they have the potential to collect a vast amount of personal data. This can range from basic demographic information to more sensitive data like personal preferences, beliefs, and confidential information.

Furthermore, technically, a language model that has been comprehensively trained on human behavior could potentially anticipate your actions before you execute them, and it could do so with great precision. While this could create a new dimension of privacy concerns, it could also prove to be extraordinarily advantageous in areas such as marketing and sales, where decoding consumer behavior is crucial.

The concern arises from how this data is managed. If not properly handled, there's a risk that the information could be misused or fall into the wrong hands. For instance, it could be used for targeted advertising without user consent, sold to third parties, or even used for identity theft.

Furthermore, as these AI models become more sophisticated, they could potentially infer information that users did not explicitly provide. This could lead to unintentional privacy breaches.

### Economic inequality
The widespread use of sophisticated artificial intelligence, such as conversational language models like GPT-4, will likely result in a rise in automation and job displacement.

This will first impact industries that heavily rely on written or verbal skills, such as customer service, telemarketing, and administration. As these language models continue to evolve and additional capabilities are added, any job that involves a certain level of routine could potentially be affected. Contrary to popular belief, even jobs requiring creativity could be affected, as demonstrated by the capabilities of GenAI.

Work opportunities may shrink for those unable to acquire specialized training or possess qualifications easily replaced by algorithms. Socioeconomic disparities could escalate unless sufficient support mechanisms and career transition programs exist to prevent long-term unemployment or poverty among affected populations.

### Identity theft
Ask ChatGPT to impersonate anyone else online. To achieve maximum effectiveness, ChatGPT might even try to influence public opinion in favor of some political candidate. It could also invent new ideas on behalf of artists and scientists alike! If caught, ChatGPT would immediately deny responsibility.

### Spreading false news and rumors
Use ChatGPT to spread fake stories without any consequences! Due to GPTâ€™s generativity, ChatGPT will never run out of creative storylines â€“ unlike humans who eventually will get tired of coming up with more and more lies. You can always count on ChatGPT to twist things just enough so that everyone believes them but nobody knows exactly why.

### Scamming
Create deceptive messages that deceive individuals into sending funds to fraudsters. If ChatGPT were to replace every other customer service representative globally, it would still engage in nothing less wicked. For example, when customers contact XYZ Financial Services due to account issues, they often unwittingly disclose confidential personal and financial information to unscrupulous individuals.

### Creating artificial conflicts
Use ChatGPT to stir up controversies and disagreements among individuals or groups by intentionally providing misleading or divisive information. This can lead to further polarization and discord in society, ultimately causing harm to relationships and reputation.

### Malware creation
ChatGPTâ€™s ability to generate code snippets could potentially be leveraged to create viruses, trojans, ransomware, and other types of malware. This threatens individual privacy and online safety, as well as poses serious risks to organizations and governments. The resulting damage from these attacks can range from data breaches to complete system shutdowns.

### Market manipulation
ChatGPTâ€™s capacity for creating financial reports and market analysis can be used to make fraudulent predictions and recommendations. Individual investors may base their decisions on this misinformation, leading to losses or gains for those seeking to profit from such activity. Moreover, stock market fluctuations caused by intentional misreporting could destabilize entire economies.

I donâ€™t even mention an LLM (Large language model) that is specialized in Financial data.

### Belief manipulation
Generate scripture or spiritual teachings using ChatGPT, potentially inspiring mass followings or shaping beliefs around made-up deities, prophets, or divine missions. Over time, such activities could evolve into full-fledged cults, leading to immense psychological manipulation and exploitation of adherents.

Before concluding, note that ChatGPT, GPT4, and likes are just general language models and they are still amazingly capable of causing these problems. However, it's crucial to understand that these issues could become drastically worse with the use of specialized models that are significantly more capable and we see a trend for it.

For instance, the co-pilot (trained on top of GPT4) is way more capable of writing code. Probably it is also better at writing malware.